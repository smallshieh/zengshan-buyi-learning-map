import os
import sys

sys.stdout.reconfigure(encoding='utf-8')

# Source File
source_file = os.path.join(os.getcwd(), 'legacy_docs', '增刪卜易.txt')
cases_dir = os.path.join(os.getcwd(), 'cases')

# Mappings: (Keyword/Title, Category, EnglishPrefix)
# "Second Batch" from Plan + Variations
# 1. 占痘 (Smallpox) -> Category: 疾病 (Disease)
# 2. 占病源 (Source of Illness) -> Category: 疾病
# 3. 占延醫 (Doctor) -> Category: 疾病
# 4. 占開店 (Opening Shop) -> Category: 求財 (Wealth)
# 5. 占借貸 (Borrowing) -> Category: 求財
# 6. 六畜 (Livestock) -> Category: 求財

targets = [
    {"kw": "占痘", "cat": "疾病", "file_desc": "占痘_特殊疾病"},
    {"kw": "占病源", "cat": "疾病", "file_desc": "占病源_病因判斷"},
    {"kw": "占延醫", "cat": "疾病", "file_desc": "占延醫_醫藥疾病"},
    {"kw": "占開店", "cat": "求財", "file_desc": "占開店_長期求財"},
    {"kw": "占借貸", "cat": "求財", "file_desc": "占借貸_財物往來"},
    {"kw": "六畜", "cat": "求財", "file_desc": "占買賣六畜_特殊財物"}
]

try:
    with open(source_file, 'r', encoding='utf-8') as f:
        content = f.read()
except UnicodeDecodeError:
    with open(source_file, 'r', encoding='gb18030') as f:
        content = f.read()

print(f"Loaded source: {len(content)} chars")

created_count = 0

for target in targets:
    kw = target["kw"]
    cat_dir = os.path.join(cases_dir, target["cat"])
    if not os.path.exists(cat_dir):
        os.makedirs(cat_dir)
        
    start_search = 0
    # Find up to 2 instances per keyword to be safe, or just 1?
    # Let's find 1 for now to avoid duplicates
    
    idx = content.find(kw)
    if idx != -1:
        # Extract a chunk of text around it (e.g. 50 chars before, 1000 after)
        # We rely on AI later to parse the exact start/end, so capturing a loose chunk is fine
        start_chunk = max(0, idx - 50)
        end_chunk = min(len(content), idx + 1000)
        
        extracted_text = content[start_chunk:end_chunk]
        
        # Create a raw MD file
        # Naming convention: case_XXX_<desc>.md
        # We don't have XXX id yet, let's use a placeholder or next available ID?
        # Let's use 'temp_' prefix and let the refactor script handle IDs later, or use 900+
        
        filename = f"case_new_{target['file_desc']}.md"
        filepath = os.path.join(cat_dir, filename)
        
        # Wrap in a prompt-friendly format for process_book.py
        file_content = f"""
# {target['file_desc']}

## Raw Text
{extracted_text}

---
Generated by extract_batch2.py using keyword '{kw}'
"""
        with open(filepath, 'w', encoding='utf-8') as out:
            out.write(file_content)
        
        print(f"Created: {filepath}")
        created_count += 1
    else:
        print(f"Keyword '{kw}' not found!")

print(f"Total files created: {created_count}")
